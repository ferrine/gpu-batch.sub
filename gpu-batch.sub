#!/usr/bin/env python3
from typing import *
import configparser
import tempfile
from itertools import islice, chain
from string import Template
import argparse
import io
import os
import re
import pathlib
__version__ = '0.0.3'

CONFIG_PATH_DEFAULT = str(pathlib.Path.home()/'.gpubatch.conf')
ARGS_NAME_DEFAULT = '$(basename `pwd`)'
HOSTS_SUB_REGEX = re.compile('( |,)+')

DESCRIPTION = """
%(prog)s is a util to wrap submissions to LSF in a batch. It automatically
collects jobs, prepares submission file you can check beforehand with `--debug` flag.
`gpu-batch.sub` asks LSF for desired number of GPU per batch and allocates them in 
shared or exclusive (not recommended) mode.
"""
EPILOG = """
Default settings are stored in `$HOME/.gpubatch.conf`.
They will override the help message as well. Possible settings for config file:
batch, gpu, hosts, header, queue. Header will be appended to LSF submission file as is, 
there is no default extra header.
"""


class Command(object):
    """
    Single command that requires output redirect
    """
    COMMAND_TEMPLATE = Template("${command} >\\\n  ${out}/${name}-${LSB_JOBID}-${i}.${j}.${k}${suffix}.out "
                                "2> ${err}/${name}-${LSB_JOBID}-${i}.${j}.${k}${suffix}.err")
    COMMAND_REGEX = re.compile(
        r'^((?:\s+)?(?P<suffix>[_a-zA-Z0-9-.]+)(?:\s+)?:)?((?:\s+)?(?P<command>(?:.|\n|\r)+)(?:\s+)?)?')

    def __init__(self, command):
        command = self.COMMAND_REGEX.match(command).groupdict()
        self.suffix = command['suffix']
        self.command = command['command']

    def format(self, i, j, k):
        return self.COMMAND_TEMPLATE.safe_substitute(
            command=self.command,
            suffix=(('-' + self.suffix) if self.suffix is not None else ''),
            i=i, j=j, k=k
        )


class Job(object):
    """
    A bunch of commands that run sequentially
    ```
    {
    command1 ;
    command2 ;
    ...
    }
    ```
    """
    def __init__(self, command: Command, *more: Command):
        self.commands = (command, ) + more

    def format(self, i, j):
        out = io.StringIO()
        out.write('{\n')
        for k, command in enumerate(self.commands):
            out.write(command.format(i=i, j=j, k=k))
            out.write(' ;\n')
        out.write('}')
        return out.getvalue()


class BatchJobs(object):
    """
    Jobs that run in parallel
    ```
    {
    command0.0.0 ;
    command0.0.1 ;
    ...
    } &
    {
    command0.1.0 ;
    command0.1.1 ;
    ...
    } &
    wait
    ```
    """
    def __init__(self, job: Job, *more: Job):
        self.jobs = (job, ) + more

    def format(self, i):
        out = io.StringIO()
        for j, job in enumerate(self.jobs):
            out.write(job.format(i=i, j=j))
            out.write(' & ')
        out.write('wait')
        return out.getvalue()


class Submit(object):
    BSUB_PREAMBLE = """\
#!/bin/sh
#BSUB -q $queue
#BSUB -n $gpu
#BSUB -J $name
#BSUB -gpu "num=$gpu:mode=$gpu_mode"
#BSUB -o $out/$name-%J-stats.out
"""
    BSUB_WORKING_DIR = """\
cd ${LS_SUBCWD}
mkdir -p $out
mkdir -p $err
"""

    def __init__(self, batch: BatchJobs, i):
        self.i = i
        self.batch = batch

    def format(
            self, name: str,
            out: pathlib.Path,
            err: pathlib.Path,
            queue: str,
            hosts: str,
            gpu: int,
            gpu_mode: str,
            header: str):
        sh = io.StringIO()
        sh.write(self.BSUB_PREAMBLE)
        if hosts:
            sh.write('#BSUB -m "%s"' % hosts)
            sh.write('\n')
        if header:
            sh.write(header)
            sh.write('\n')
        sh.write(self.BSUB_WORKING_DIR)
        sh.write(self.batch.format(i=self.i))
        return Template(sh.getvalue()).safe_substitute(
            out=out, err=err, queue=queue, name=name,
            gpu=gpu, gpu_mode=gpu_mode
        )


def commands_from_file_lines(lines: Iterable[str], *, force_sequential=False) -> Iterable[Iterable[str]]:
    commands = [[]]
    buffer = ''
    parallel = not force_sequential
    for line in filter(lambda s: bool(s.strip()), lines):
        # remove comments and rstrip
        line = line.split('#', 1)[0]
        if not line:
            if buffer:
                commands[-1].append(buffer)
                if parallel:
                    commands.append([])
            buffer = ''
            continue
        else:
            line = line.rstrip()
        if line.endswith('\\'):
            # next line is the continuation of the command
            # add line tu buffer, add multiline and continue
            buffer += line + '\n'
        elif line.strip() == '<sequential>' and not force_sequential:
            assert parallel, 'Wrong syntax, <sequential> followed by <sequential>'
            parallel = False
            continue
        elif line.strip() == '</sequential>' and not force_sequential:
            assert not parallel, 'Wrong syntax, </sequential> followed by </sequential>'
            parallel = True
            commands.append([])
        else:
            if line:
                buffer += line
            # empty line new command next
            # add job, free buffer and continue
            commands[-1].append(buffer)
            buffer = ''
            if parallel:
                commands.append([])
    commands.pop(-1)
    return commands


def to_batch(iterable: Iterable, n: int):
    if n == -1:
        yield iter(iterable)
    else:
        sourceiter = iter(iterable)
        while True:
            batchiter = islice(sourceiter, n)
            yield chain([next(batchiter)], batchiter)


if __name__ == '__main__':
    defaults = dict()
    if os.path.exists(CONFIG_PATH_DEFAULT):
        conf = configparser.ConfigParser(comment_prefixes=(';',))
        conf.read([CONFIG_PATH_DEFAULT])
        defaults.update(conf.items('gpubatch'))
    parser = argparse.ArgumentParser(description=DESCRIPTION, epilog=EPILOG,
                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('--batch', '-b', type=int,
                        default=defaults.get('batch', -1),
                        help='Number of jobs in batch where -1 stands for unlimited batch')
    parser.add_argument('--sequential', '-s',
                        action='store_true',
                        help='Make all jobs sequential within bsub submit')
    parser.add_argument('--gpu', '-g', type=int,
                        default=defaults.get('gpu', 1),
                        help='Number of gpu per batch')
    parser.add_argument('--out', '-o', type=pathlib.Path,
                        default=defaults.get('out', pathlib.Path('bsub-log', 'out')),
                        help='Output path for stdout')
    parser.add_argument('--err', '-e', type=pathlib.Path,
                        default=defaults.get('err', pathlib.Path('bsub-log', 'err')),
                        help='Output path for stderr')
    parser.add_argument('--name', '-n', type=str,
                        default=ARGS_NAME_DEFAULT,
                        help='Name for job, defaults to base directory of execution')
    parser.add_argument('--hosts', type=str,
                        default=defaults.get('hosts', ''),
                        help='Space or comma separated allowed hosts. '
                             'Empty string holds for ALL visible hosts. '
                             'It is suggested to specify hosts in `.conf` file. '
                             'Passing hosts in command line looks like '
                             "`--hosts ''` for ALL or `--hosts 'host1,host2'` for 2 hosts")
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument('--files', '-f', type=argparse.FileType('r'), nargs='+',
                       default=[],
                       help='Read jobs from files. File can contain multiline jobs for readability')
    group.add_argument('jobs', nargs='*', type=str,
                       default=[],
                       help="Jobs to execute (e.g. 'python script.py') enclosed as strings, "
                            "you can specify either files or explicit jobs in command line. "
                            "Multiline jobs in files are supported. Optional naming schema for jobs has "
                            "the following syntax 'name:command'")
    parser.add_argument('--queue', '-q', type=str,
                        default=defaults.get('queue', 'normal'),
                        help='Queue name')
    parser.add_argument('--exclusive', '-x', action='store_const',
                        default='shared',
                        const='exclusive_process',
                        dest='gpu_mode',
                        help='Exclusive GPU mode is possible but not recommended in most cases. Exclusive mode '
                             'allocates GPU only for 1 separate process. As a side effect it '
                             'breaks batched jobs and applicable only for 1 job per batch')
    parser.add_argument('--debug', action='store_true',
                        help='Print submissions and exit')
    parser.add_argument('--version', action='store_true',
                        help='Print version and exit')
    args = parser.parse_args()
    if args.version:
        import sys
        print(__version__)
        sys.exit(0)
    if args.files:
        args.jobs = sum((commands_from_file_lines(f.readlines()) for f in args.files), [])
    else:
        args.jobs = [[job] for job in args.jobs]
    if args.name == ARGS_NAME_DEFAULT:
        args.name = pathlib.Path.cwd().name
    if args.hosts:
        args.hosts = HOSTS_SUB_REGEX.sub(' ', args.hosts)
    if args.sequential:
        batches = ((Job(*(Command(c) for c in commands)), )
                   for commands in
                   to_batch(sum(args.jobs, []), args.batch))
    else:
        batches = to_batch([
            Job(*(Command(c) for c in commands))
            for commands in args.jobs],
            args.batch)
    submits = [Submit(BatchJobs(*b), i) for i, b in enumerate(batches)]
    params = dict(
        out=args.out,
        err=args.err,
        hosts=args.hosts,
        queue=args.queue,
        gpu=args.gpu,
        gpu_mode=args.gpu_mode,
        name=args.name,
        header=defaults.get('header', '')
    )
    if args.debug:
        for i, submit in enumerate(submits):
            print('>' * 10)
            print('#SUBMIT:', i)
            print('v' * 10)
            print(submit.format(**params))
    else:
        for submit in submits:
            with tempfile.NamedTemporaryFile('w', delete=False) as f:
                f.write(submit.format(**params))
                f.close()
                os.system('bsub < ' + f.name)
                os.unlink(f.name)
